{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"phase_2_processor.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNkwId3k3TzzkCnXvH8FPXN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"czEilh6CDvR4","colab_type":"code","colab":{}},"source":["!git clone https://github.com/16cs009/alyceproject.git\n","import os\n","os.chdir(\"/content/alyceproject\")\n","!pip install -r requirements.txt\n","\n","from transformers.modeling_gpt2 import GPT2LMHeadModel\n","_ = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n","\n","!pip install \"python-socketio[client]\"\n","\n","\n","import numpy as np\n","import torch\n","import plot_generator\n","from Datasets import datasets\n","tokenizer, model, PPLM = plot_generator.initialize(np,torch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ULlMl9UFC9x","colab_type":"code","colab":{}},"source":["def phaseII_processStory(storylist):\n","\t# Returns a list of list with the following as the content of list inside the list :>\n","\t# 1. Dialogue-Replaced sentence from story or Generated PLOT\n","\t# 2. Type of the Sentence : NARRATION, DIALOGUE, NEWLINE, PLOT\n","\t# 3. YES or NO string indicating whether NeuralCoref was applied to resolve reference\n","\t# 4. If NeuralCoref was applied then The object It returned\n","\t# 5. If the sentence is of type dialogue then its speaker\n","\t# 6. If the sentence is of type dialogue then the corresponding dialogue\n","\tplotwords = []\n","\ttmp = list()\n","\tnew_storylist = []\n","\ttmp_storylist = []\n","\tp_count = 0\n","\tfor sentences in storylist:\n","\t\ttmp_storylist.append(sentences)\n","\t\tif sentences[1]==\"NEWLINE\":\n","\t\t\tif len(tmp_storylist)>0:\n","\t\t\t\tnew_storylist.append([p_count,\"PLOT\",\"\",\"\",\"\",\"\"])\n","\t\t\t\tp_count = p_count + 1\n","\t\t\tnew_storylist += tmp_storylist\n","\t\t\ttmp_storylist = []\n","\t\t\tplotwords.append(tmp)\n","\t\t\ttmp = list()\n","\t\telif sentences[1]==\"NARRATIVE\":\n","\t\t\ttmp = tmp + sentences[0].split(\" \")\n","\t\telse:\n","\t\t\ttmp = tmp + sentences[0].split(\" \")\n","\t\t\ttmp = tmp + sentences[5].split(\" \")\n","\t#print(new_storylist)\n","\tfor i in range(len(plotwords)):\n","\t\tplotwords[i] = list(dict.fromkeys([ (\"\".join([tmpchar for tmpchar in word if tmpchar.isalpha()==True])).lower() for word in plotwords[i] if word.find(\"<-DIALOGUE-#\")==-1 and len(word)>2 and word not in datasets.wordList]))\n","\t\tplotwords[i].sort()\n","\tplot_desc = []\n","\tprint(\"Required to genearte \"+str(len(plotwords)+1)+\" words!...\")\n","\tfor i in plotwords:\n","\t\tif len(i)>0:\n","\t\t\tprint(\"Generating Plot!....\")\n","\t\t\tplot_desc.append(plot_generator.generate_plot(np,torch,tokenizer,model,PPLM,[i],20,1)[0])\n","\t\t\tprint(\"Generating Plot Completed!....\")\n","\t\telse:\n","\t\t\tplot_desc.append('')\n","\tnew_storylist = [sentences if sentences[1]!=\"PLOT\" else [plot_desc[sentences[0]],\"PLOT\",\"\",\"\",\"\",\"\"] for sentences in new_storylist]\n","\treturn new_storylist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Brj2QYSlxvwy","colab_type":"code","colab":{}},"source":["def phaseII_processStory_Step_1(storylist):\n","\t# Returns a new_storylist and plotwords\n","\tplotwords = []\n","\ttmp = list()\n","\tnew_storylist = []\n","\ttmp_storylist = []\n","\tp_count = 0\n","\tfor sentences in storylist:\n","\t\ttmp_storylist.append(sentences)\n","\t\tif sentences[1]==\"NEWLINE\":\n","\t\t\tif len(tmp_storylist)>0:\n","\t\t\t\tnew_storylist.append([p_count,\"PLOT\",\"\",\"\",\"\",\"\"])\n","\t\t\t\tp_count = p_count + 1\n","\t\t\tnew_storylist += tmp_storylist\n","\t\t\ttmp_storylist = []\n","\t\t\tplotwords.append(tmp)\n","\t\t\ttmp = list()\n","\t\telif sentences[1]==\"NARRATIVE\":\n","\t\t\ttmp = tmp + sentences[0].split(\" \")\n","\t\telse:\n","\t\t\ttmp = tmp + sentences[0].split(\" \")\n","\t\t\ttmp = tmp + sentences[5].split(\" \")\n","\t#print(new_storylist)\n","\tfor i in range(len(plotwords)):\n","\t\tplotwords[i] = list(dict.fromkeys([ (\"\".join([tmpchar for tmpchar in word if tmpchar.isalpha()==True])).lower() for word in plotwords[i] if word.find(\"<-DIALOGUE-#\")==-1 and len(word)>2 and word not in datasets.wordList]))\n","\t\tplotwords[i].sort()\n","\tnew_storylist = [sentences if sentences[1]!=\"PLOT\" else [\"\",\"PLOT\",plotwords[sentences[0]],[],\"\",\"\"] for sentences in new_storylist]\n","\treturn new_storylist\n","\n","\"\"\"\n","def phaseII_processStory_Step_2(plotwords):\n","\t# Returns a list of strings(PLOTS) as the content.\n","\tplot_desc = []\n","\tprint(\"Required to genearte \"+str(len(plotwords)+1)+\" words!...\")\n","\tfor i in plotwords:\n","\t\tif len(i)>0:\n","\t\t\tprint(\"Generating Plot!....\")\n","\t\t\tplot_desc.append(plot_generator.generate_plot(np,torch,tokenizer,model,PPLM,[i],20,1)[0])\n","\t\t\tprint(\"Generating Plot Completed!....\")\n","\t\telse:\n","\t\t\tplot_desc.append('')\n","\treturn plot_desc\n","\"\"\"\n","\n","def phaseII_processStory_Step_2(plotwords):\n","\t# Returns a list of strings(PLOTS) as the content.\n","\tplot_desc = []\n","\tprint(\"Required to genearte \"+str(len(plotwords)+1)+\" words!...\")\n","\tfor i in plotwords:\n","\t\tif len(i[1])>0:\n","\t\t\tprint(\"Generating Plot!....\")\n","\t\t\ttmp = []\n","\t\t\ttmp.append(i[0])\n","\t\t\ttmp.append(plot_generator.generate_plot(np,torch,tokenizer,model,PPLM,[i[1]],20,1)[0])\n","\t\t\tplot_desc.append(tmp)\n","\t\t\tprint(\"Generating Plot Completed!....\")\n","\t\telse:\n","\t\t\tplot_desc.append([i[0],''])\n","\treturn plot_desc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxdQbMuwEPXa","colab_type":"code","colab":{}},"source":["import socketio\n","import json\n","import time\n","\n","sio = socketio.Client()\n","\n","\"\"\"def workHandler(input_data):\n","\tsio.emit('phase-2-server-to-main-server',{\"client\": input_data[\"client\"], \"procedureNo\": input_data[\"procedureNo\"], \"status\": \"STARTED\", \"output\": json.dumps([[\"None\"]])})\n","\toutput_data = phaseII_processStory(input_data[\"input\"])\n","\t#sio.sleep(30);\n","\tsio.emit('phase-2-server-to-main-server',{\"client\": input_data[\"client\"], \"procedureNo\": input_data[\"procedureNo\"], \"status\": \"COMPLETED\", \"output\": json.dumps(output_data)})\"\"\"\n","\n","def workHandler(input_data):\n","\tsio.emit('phase-2-server-to-main-server',{\"client\": input_data[\"client\"], \"procedureNo\": input_data[\"procedureNo\"], \"status\": \"STARTED\", \"output\": json.dumps([[\"None\"]])})\n","\toutput_data = []\n","\tif(input_data[\"procedureNo\"]==0):\n","\t\toutput_data = phaseII_processStory_Step_1(input_data[\"input\"])\n","\telif(input_data[\"procedureNo\"]==1):\n","\t\toutput_data = phaseII_processStory_Step_2(input_data[\"input\"])\n","\t#sio.sleep(30);\n","\tprint(\"Return Data : \"+str(json.dumps(output_data)))\n","\tsio.emit('phase-2-server-to-main-server',{\"client\": input_data[\"client\"], \"procedureNo\": input_data[\"procedureNo\"], \"status\": \"COMPLETED\", \"output\": json.dumps(output_data)})\n","\n","@sio.on('main-server-to-phase-2-server')\n","def on_phaseTwoData(data):\n","\tprint(\"RECEIVED DATA : {}\".format(data))\n","\tsio.start_background_task(workHandler, data)\n","\n","print(\"Starting Sub server of Phase 2 !...\")\n","sio.connect(input(\"Enter NGROK Link : \"))\n","sio.emit('server-ready',{\"phase\": 2})\n","print(\"Started Sub server of Phase 2 !...\")\n","\n","try:\n","\twhile True:\n","\t\ttime.sleep(1)\n","except KeyboardInterrupt:\n","\tprint(\"Interrupt Received!...\")\n","\tsio.disconnect()\n","\n","print(\"Exiting Sub Server!....\")"],"execution_count":0,"outputs":[]}]}